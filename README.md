# PPGPT

<div align="center">

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

*A comprehensive system for predicting physiological parameters from PPG signals using deep learning*

[Quick Start](#quick-start) â€¢ [Documentation](#documentation) â€¢ [Examples](#examples) â€¢ [Paper](#citation)

</div>

---

## ğŸŒŸ Features

- **ğŸ”€ Multi-Modal Learning**: Dual-stream encoder for signal and spatial features
- **ğŸ‘¥ Multi-Expert Architecture**: Specialized networks for different physiological parameters
- **ğŸ¤– Transformer Models**: State-of-the-art attention mechanisms for PPG analysis
- **ğŸ“Š Comprehensive Evaluation**: Built-in metrics and visualization tools
- **ğŸš€ Easy Deployment**: Docker support and streamlined workflows
- **âš¡ High Performance**: Optimized for both accuracy and efficiency

## ğŸš€ Quick Start

### 1. Installation
```bash
pip install -r requirements.txt
pip install -e .
```

### 2. Run Example
```bash
python scripts/preprocess_data.py --input_path sample_data.csv
python scripts/train.py --config configs/dual_stream_config.yaml
python scripts/evaluate.py --config configs/dual_stream_config.yaml --model_path outputs/final_model.pth
```

### 3. Full Experiments
```bash
# Run all experiments with evaluation
python scripts/run_experiments.py --experiments all --evaluate
```

## ğŸ“ Project Structure

```
ppg-physiological-prediction/
â”œâ”€â”€ ğŸ“¦ config/                 # Configuration files
â”‚   â”œâ”€â”€ model_config.py        # Model configurations
â”‚   â””â”€â”€ expert_config.py       # Expert network configs
â”œâ”€â”€ ğŸ“Š data/                   # Data processing
â”‚   â”œâ”€â”€ dataset.py             # Dataset classes
â”‚   â”œâ”€â”€ preprocessing.py       # Signal preprocessing
â”‚   â””â”€â”€ data_generator.py      # Data generation pipeline
â”œâ”€â”€ ğŸ§  models/                 # Model architectures
â”‚   â”œâ”€â”€ dual_stream_encoder.py # Multi-modal encoder
â”‚   â”œâ”€â”€ expert_model.py        # Multi-expert networks
â”‚   â”œâ”€â”€ transformer_model.py   # Transformer models
â”‚   â””â”€â”€ base_model.py          # Base model class
â”œâ”€â”€ ğŸ¯ training/               # Training utilities
â”‚   â”œâ”€â”€ trainer.py             # Training loops
â”‚   â””â”€â”€ losses.py              # Loss functions
â”œâ”€â”€ ğŸ”§ utils/                  # Utilities
â”‚   â”œâ”€â”€ metrics.py             # Evaluation metrics
â”‚   â”œâ”€â”€ visualization.py       # Plotting functions
â”‚   â””â”€â”€ feature_extraction.py  # Feature extraction
â”œâ”€â”€ ğŸ“œ scripts/                # Execution scripts
â”‚   â”œâ”€â”€ train.py               # Training script
â”‚   â”œâ”€â”€ evaluate.py            # Evaluation script
â”‚   â””â”€â”€ run_experiments.py     # Experiment runner
â”œâ”€â”€ âš™ï¸ configs/                # YAML configurations
â”œâ”€â”€ ğŸ§ª tests/                  # Unit tests
â””â”€â”€ ğŸ“– docs/                   # Documentation
```

## ğŸ—ï¸ Model Architectures

### ğŸ”€ Dual-Stream Encoder
Processes both 1D PPG signals and 2D spatial representations:
```python
from models.dual_stream_encoder import DualStreamEncoder

model = DualStreamEncoder(
    signal_dim=600,
    image_channels=3,
    output_dim=256
)
```

### ğŸ‘¥ Multi-Expert Model
Specialized experts for different physiological parameters:
```python
from models.expert_model import MultiExpertModel

model = MultiExpertModel(
    input_dim=256,
    expert_names=['SBP', 'DBP', 'HR', 'GLU']
)
```

### ğŸ¤– Transformer Model
Attention-based sequence modeling:
```python
from models.transformer_model import PPGTransformer

model = PPGTransformer(
    input_dim=600,
    d_model=256,
    num_heads=8,
    num_layers=6
)
```

## âš™ï¸ Configuration

### Model Configuration
```yaml
# configs/dual_stream_config.yaml
model:
  type: dual_stream
  config:
    signal_dim: 600
    image_channels: 3
    output_dim: 256

training:
  batch_size: 64
  epochs: 100
  optimizer:
    type: adamw
    lr: 1e-3
```

### Custom Configuration
```python
from config.model_config import ModelConfig

config = ModelConfig(
    signal_dim=600,
    hidden_dim=256,
    num_heads=8
)
```

### Data Preprocessing
```bash
python scripts/preprocess_data.py \
    --input_path raw_data.csv \
    --output_dir processed_data \
    --signal_length 600 \
    --quality_check
```

## ğŸ¯ Training & Evaluation

### Training
```bash
# Single model training
python scripts/train.py --config configs/dual_stream_config.yaml
```

### Evaluation
```bash
# Evaluate with visualization
python scripts/evaluate.py \
    --config configs/dual_stream_config.yaml \
    --model_path model.pth \
    --visualize
```

### Metrics
- **MAE**: Mean Absolute Error
- **RMSE**: Root Mean Square Error  
- **MAPE**: Mean Absolute Percentage Error
- **RÂ²**: Coefficient of Determination
- **Pearson**: Pearson Correlation Coefficient

## ğŸ§ª Testing

```bash
# Run all tests
make test

# With coverage
make test-coverage

# Specific test
python -m pytest tests/test_models.py -v
```

## ğŸ“š API Reference

### Core Classes
- `DualStreamEncoder`: Multi-modal signal processing
- `MultiExpertModel`: Multi-task prediction
- `PPGTransformer`: Attention-based modeling
- `Trainer`: Training orchestration
- `MetricsTracker`: Performance monitoring

### Key Functions
- `preprocess_ppg_signal()`: Signal preprocessing
- `generate_spatial_features()`: Spatial feature extraction  
- `calculate_metrics()`: Evaluation metrics
- `plot_predictions_vs_actual()`: Visualization

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“– Citation

If you use this code in your research, please cite:

```bibtex
@article{,
  title={},
  author={},
  journal={},
  year={},
  volume={},
  pages={}
}
```

## ğŸ™ Acknowledgments

- PyTorch team for the deep learning framework
- Contributors to the PPG signal processing community
- Research institutions supporting this work

---

<div align="center">

**[â­ Star this repo]()** if it helped you!

Made with â¤ï¸ by the PPG Research Team

</div>
